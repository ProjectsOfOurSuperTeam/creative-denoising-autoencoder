# Проміжний звіт з проєкту

**Команда:** Creative CV  
**Тема:** Denoising Autoencoder для очищення старих та зашумлених фотографій  
**Дата:** 01.03.2026

---

## 1. Загальний огляд: що було зроблено

### 1.1 Підготовка даних

- Зібрано та інтегровано два датасети:
  - **Denoising Dirty Documents** (Kaggle) — 144 пари «зашумлене / чисте» зображення документів (grayscale) + 72 тестових зображення.
  - **DIV2K** — 800 HR-зображень для навчання та 100 для валідації (кольорові, високої роздільної здатності).
- Реалізовано автоматичний конвеєр розархівації та нормалізації структури папок (рекурсивне розпакування вкладених `.zip`, усунення дубльованих вкладеностей типу `test/test/`).
- Реалізовано детерміноване розділення на train/val (90/10) з фіксованим seed для відтворюваності.

### 1.2 Синтетична деградація

Для навчання на DIV2K реалізовано конвеєр синтетичних деградацій, які застосовуються випадково:

| Деградація | Ймовірність | Параметри |
|---|---|---|
| Gaussian noise | 80% | σ ∈ [5, 50] |
| Gaussian blur | 50% | kernel ∈ {3, 5, 7} |
| JPEG-артефакти | 50% | quality ∈ [10, 60] |
| Downscale → Upscale | 30% | factor ∈ {2, 4} |

### 1.3 Exploratory Data Analysis (EDA)

Проведено повний EDA-прохід (12 секцій), зокрема:

- Огляд структури датасетів (кількість зображень, розміри, канали).
- Розподіл розмірів зображень (гістограми width/height).
- Візуалізація пар noisy/clean + різниця (карта шуму).
- Розподіл інтенсивності пікселів (noisy vs clean, агрегований).
- Статистика шуму (mean, std, skewness) по кожному зображенню.
- **Baseline PSNR / SSIM** — метрики до будь-якої обробки (noisy vs clean).
- FFT-аналіз частотного спектру шуму.
- Кореляція PSNR-SSIM.

### 1.4 Моделі

Реалізовано три архітектури нейронних мереж:

| Модель | Тип | Ключова ідея |
|---|---|---|
| **CDAE** | Convolutional Denoising Autoencoder | Encoder-decoder з residual head (вихід = input + prediction) |
| **DnCNN** | Deep CNN for denoising | Residual learning — мережа передбачає шум, який віднімається від входу |
| **U-Net** | U-Net (compact) | Skip-connections між encoder та decoder для збереження дрібних деталей |

Усі моделі мають уніфікований інтерфейс (`build_model(name, in_channels)`) для спільного training/eval циклу.

### 1.5 Навчання та оптимізація гіперпараметрів

- Реалізовано повний training pipeline з:
  - SmoothL1Loss
  - AdamW оптимізатор
  - ReduceLROnPlateau scheduler
  - Gradient clipping (max_norm=5.0)
  - Early stopping
  - Автоматичне збереження чекпоінтів (`best.pt`)
- **Optuna HPO** — для кожної моделі проведено пошук гіперпараметрів (15 trials × 5 epochs) з MedianPruner:
  - Оптимізовані параметри: `lr`, `weight_decay`, `smooth_l1_beta`, `sched_patience`, `sched_factor`, а також архітектурні (`depth`, `width`, `base`).
- Після HPO проведено фінальне навчання з найкращими параметрами (до 30 епох з patience=10).
- Навчання проводилось на **об'єднаному датасеті** (Denoising Documents + DIV2K grayscale).

### 1.6 Інференс та порівняння

- Завантаження найкращих чекпоінтів для кожної моделі.
- Порівняння PSNR/SSIM на валідаційних батчах (Denoising Documents + DIV2K grayscale).
- Візуальне порівняння: noisy → prediction → clean для кожної моделі.

### 1.7 Frontend (демо-додаток)(зараз не працює)

- Створено Streamlit-додаток (`frontend/app_streamlit.py`) із:
  - Завантаження зображення.
  - Вибір моделі (CDAE / DnCNN / U-Net).
  - Порівняння результатів усіх моделей.
  - Можливість завантажити відновлений результат.
  - Інформаційна сторінка "Про проєкт".

---

## 2. Що спрацювало

- **Конвеєр синтетичної деградації** добре імітує реальні артефакти — моделі навчились на DIV2K і одночасно показують результат на реальних документах.
- **Об'єднання датасетів** (Denoising Documents + DIV2K grayscale) покращило генералізацію моделей.
- **Optuna HPO** дозволив автоматично підібрати оптимальні параметри для кожної архітектури, що суттєво покращило baseline метрики.
- **Residual learning** (в усіх трьох моделях вихід = input + learned_residual) стабілізував навчання.
- **Early stopping + ReduceLROnPlateau** запобігли перенавчанню.
- **Уніфікований API** для train/eval дозволив швидко порівнювати моделі без дублювання коду.

---

## 3. Що не спрацювало / проблеми

- **LPIPS метрика** — поки не інтегрована в пайплайн оцінки (залежність `lpips` закоментована в `requirements.txt`). Планується додати.
- **SwinIR / Restormer** — трансформерні архітектури не реалізовані в поточній версії через обмеження часу та ресурсів GPU. Розглядаються як можливе розширення.
- **Streamlit фронтенд** — наразі використовує OpenCV-заглушку (`cv2.fastNlMeansDenoisingColored`) замість реальних навчених моделей для інференсу. Потрібна інтеграція PyTorch-моделей.
- **Шум Пуассона та імпульсний шум** — згадані в описі проєкту, але поки не реалізовані в конвеєрі деградацій (є тільки Gaussian noise, blur, JPEG-артефакти, downscale).
- **Кольоровий режим** — моделі навчались переважно на grayscale; повноцінна підтримка RGB-інференсу потребує доопрацювання.

---

## 4. Внесок кожного учасника

| Учасник | Внесок | Опис |
|---|---|---|
| **Шандрик Андрій** | Data pipeline, моделі, training (~35%) | Реалізація датасетів (`DIV2KDegradedDataset`, `DenoisingDataset`), конвеєр синтетичної деградації, training loop, збереження чекпоінтів. |
| **Тугай Анастасія** | EDA, моделі, HPO, візуалізація (~35%) | Повний EDA-блок (12 секцій), baseline PSNR/SSIM, FFT-аналіз, архітектура U-Net, Optuna HPO, графіки навчання. |
| **Швачка Денис** | Дані, аугментації, документація (~30%) | Збір та підготовка датасетів, архівація/розпакування даних, архітектури CDAE та DnCNN, аугментації (Albumentations), Streamlit-додаток, README та звіт. |

---

## 5. Витрачений час

| Етап | Орієнтовний час |
|---|---|
| Дослідження літератури, підбір та підготовка датасетів | ~4 годин |
| EDA та аналіз даних | ~8 годин |
| Реалізація моделей (CDAE, DnCNN, U-Net) | ~8 годин |
| Training pipeline + Optuna HPO + навчання | ~15 годин |
| **Загалом** | **~35 годин** (на команду) |


