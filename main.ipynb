{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1119ba9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.10.0+cu130\n",
      "CUDA available: True\n",
      "CUDA device: NVIDIA GeForce RTX 3060\n",
      "CUDA version: 13.0\n",
      "torch current device: 0\n",
      "Training device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Стандартна бібліотека\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import itertools\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict, Counter\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "import zipfile\n",
    "\n",
    "# Наукові обчислення та табличні дані\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Візуалізація\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Комп'ютерний зір та зображення\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import torch.amp\n",
    "\n",
    "# Аугментації\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Перевірка CUDA\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"torch current device: {torch.cuda.current_device()}\")\n",
    "print(f\"Training device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ffe90e",
   "metadata": {},
   "source": [
    "```\n",
    "#!/bin/bash\n",
    "curl -L -o ~/Downloads/div2k-dataset.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/joe1995/div2k-dataset\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "  https://www.kaggle.com/competitions/denoising-dirty-documents/data\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3e0d4e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = Path.cwd()\n",
    "DATA_DIR = ROOT_DIR / \"data\"\n",
    "\n",
    "# Шляхи до даних\n",
    "DENOISING_DIR = DATA_DIR / \"denoising-dirty-documents\"\n",
    "DIV2K_DIR = DATA_DIR / \"div2k-dataset\"\n",
    "\n",
    "# Шляхи до zip-архівів\n",
    "TARGET_ZIPS = [\n",
    "    ROOT_DIR / \"denoising-dirty-documents.zip\",\n",
    "    ROOT_DIR / \"div2k-dataset.zip\"\n",
    "]\n",
    "\n",
    "# Створення основної папки для даних\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# --- Функції для обробки архівів ---\n",
    "\n",
    "def unzip_recursive(zip_path: Path, extract_to: Path):\n",
    "    \"\"\"\n",
    "    Розархівовує zip-файл у вказану папку, якщо папка призначення\n",
    "    не існує або порожня.\n",
    "    \"\"\"\n",
    "    if not zip_path.exists():\n",
    "        print(f\"Zip-файл не знайдено: {zip_path.name}\")\n",
    "        return\n",
    "\n",
    "    if extract_to.exists() and any(extract_to.iterdir()):\n",
    "        print(f\"Папка {extract_to.name} вже існує і не порожня. Пропускаємо розархівацію.\")\n",
    "        return\n",
    "\n",
    "    extract_to.mkdir(parents=True, exist_ok=True)\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zf:\n",
    "            zf.extractall(extract_to)\n",
    "            print(f\"Архів {zip_path.name} успішно розархівовано у {extract_to.name}\")\n",
    "    except zipfile.BadZipFile:\n",
    "        print(f\"Пропущено пошкоджений zip-файл: {zip_path.name}\")\n",
    "        return\n",
    "\n",
    "    if zip_path.is_relative_to(DATA_DIR) and zip_path.exists():\n",
    "        zip_path.unlink()\n",
    "\n",
    "def process_zips(base_data_dir: Path):\n",
    "    \"\"\"\n",
    "    Рекурсивно шукає вкладені zip-архіви та розархівовує їх.\n",
    "    \"\"\"\n",
    "    found_zip = True\n",
    "    while found_zip:\n",
    "        found_zip = False\n",
    "        for root, _, files in os.walk(base_data_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.zip'):\n",
    "                    z_path = Path(root) / file\n",
    "                    ex_path = Path(root) / z_path.stem\n",
    "                    print(f\"Знайдено вкладений архів {z_path.name}, розархівація у {ex_path.name}\")\n",
    "                    unzip_recursive(z_path, ex_path)\n",
    "                    found_zip = True\n",
    "                    break\n",
    "            if found_zip:\n",
    "                break\n",
    "\n",
    "def flatten_duplicate_dirs(base_path: Path):\n",
    "    \"\"\"\n",
    "    Піднімає файли на рівень вище, якщо папка та вкладена в неї папка\n",
    "    мають однакові імена (щоб не було ../test/test/img).\n",
    "    \"\"\"\n",
    "    flattened_something = True\n",
    "    while flattened_something:\n",
    "        flattened_something = False\n",
    "        for root, dirs, _ in os.walk(base_path, topdown=False):\n",
    "            current_dir = Path(root)\n",
    "            if not current_dir.exists() or current_dir == base_path:\n",
    "                continue\n",
    "            \n",
    "            for d in dirs:\n",
    "                if d == current_dir.name:\n",
    "                    child_dir = current_dir / d\n",
    "                    if child_dir.exists() and child_dir.is_dir():\n",
    "                        print(f\"Злиття папок з однаковим ім'ям: {child_dir.name} -> {current_dir.name}\")\n",
    "                        for item in child_dir.iterdir():\n",
    "                            dest_path = current_dir / item.name\n",
    "                            try:\n",
    "                                shutil.move(str(item), str(dest_path))\n",
    "                            except shutil.Error as e:\n",
    "                                print(f\"Помилка переміщення {item.name} до {dest_path.name}: {e}\")\n",
    "\n",
    "                        try:\n",
    "                            child_dir.rmdir()\n",
    "                            flattened_something = True\n",
    "                        except OSError as e:\n",
    "                            print(f\"Не вдалося видалити {child_dir.name}: {e}\")\n",
    "            if flattened_something:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fbbd7789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Розархівація кореневого архіву denoising-dirty-documents.zip у denoising-dirty-documents\n",
      "Папка denoising-dirty-documents вже існує і не порожня. Пропускаємо розархівацію.\n",
      "Розархівація кореневого архіву div2k-dataset.zip у div2k-dataset\n",
      "Папка div2k-dataset вже існує і не порожня. Пропускаємо розархівацію.\n",
      "Розархівацію та структурування успішно завершено!\n"
     ]
    }
   ],
   "source": [
    "# 1. Витягуємо кореневі архіви\n",
    "for z_path in TARGET_ZIPS:\n",
    "    if z_path.exists():\n",
    "        ex_path = DATA_DIR / z_path.stem\n",
    "        print(f\"Розархівація кореневого архіву {z_path.name} у {ex_path.name}\")\n",
    "        unzip_recursive(z_path, ex_path)\n",
    "    else:\n",
    "        print(f\"Файл не знайдено (або вже розпаковано і видалено): {z_path.name}\")\n",
    "        \n",
    "# 2. Шукаємо та розархівовуємо вкладені zip (рекурсивний розархіватор)\n",
    "process_zips(DATA_DIR)\n",
    "\n",
    "# 3. Позбавляємося вкладеностей типу test/test\n",
    "flatten_duplicate_dirs(DATA_DIR)\n",
    "print(\"Розархівацію та структурування успішно завершено!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7aa99264",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DENOISING_TRAIN_DIR = DENOISING_DIR / \"train\"\n",
    "DENOISING_TEST_DIR = DENOISING_DIR / \"test\"\n",
    "DENOISING_CLEANED_DIR = DENOISING_DIR / \"train_cleaned\"\n",
    "DENOISING_SAMPLESUBMISSIONCSV = DENOISING_DIR / \"sampleSubmission.csv\"\n",
    "DIV2K_TRAIN_HR_DIR = DIV2K_DIR / \"DIV2K_train_HR\"\n",
    "DIV2K_VALID_HR_DIR = DIV2K_DIR / \"DIV2K_valid_HR\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7231982e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ── Конфігурація датасетів ─────────────────────────────────────────────\n",
    "PATCH_SIZE   = 256        # розмір кропу (H x W)\n",
    "SCALE        = 1          # 1 = той самий розмір (denoising / restoration)\n",
    "VAL_SPLIT    = 0.1        # частка валідаційних зображень\n",
    "RANDOM_SEED  = 42\n",
    "BATCH_SIZE   = 8\n",
    "NUM_WORKERS  = 4\n",
    "\n",
    "IMG_EXTENSIONS = {\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tif\", \".tiff\"}\n",
    "\n",
    "def gather_images(folder: Path) -> List[Path]:\n",
    "    \"\"\"Рекурсивно збирає всі зображення у папці.\"\"\"\n",
    "    return sorted(\n",
    "        p for p in folder.rglob(\"*\") if p.suffix.lower() in IMG_EXTENSIONS\n",
    "    )\n",
    "\n",
    "def make_split(\n",
    "    files: List[Path],\n",
    "    val_ratio: float = VAL_SPLIT,\n",
    "    seed: int = RANDOM_SEED,\n",
    ") -> Tuple[List[Path], List[Path]]:\n",
    "    \"\"\"Детерміноване перемішування та розбивка на train / val.\"\"\"\n",
    "    rng = random.Random(seed)\n",
    "    shuffled = files.copy()\n",
    "    rng.shuffle(shuffled)\n",
    "    n_val = max(1, int(len(shuffled) * val_ratio))\n",
    "    return shuffled[n_val:], shuffled[:n_val]     # (train, val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8a7f9e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ── Синтетична деградація для DIV2K ──────────────────────────────────\n",
    "def apply_degradation(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Застосовує випадковий набір деградацій до RGB-зображення (uint8).\n",
    "\n",
    "    Деградації (кожна застосовується незалежно з певною ймовірністю):\n",
    "      • Gaussian noise\n",
    "      • Gaussian blur\n",
    "      • JPEG-артефакти\n",
    "      • Downscale → Upscale (пікселізація)\n",
    "    \"\"\"\n",
    "    out = img.copy()\n",
    "\n",
    "    # Gaussian noise\n",
    "    if random.random() < 0.8:\n",
    "        sigma = random.uniform(5, 50)\n",
    "        noise = np.random.normal(0, sigma, out.shape).astype(np.float32)\n",
    "        out = np.clip(out.astype(np.float32) + noise, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # Gaussian blur\n",
    "    if random.random() < 0.5:\n",
    "        ksize = random.choice([3, 5, 7])\n",
    "        out = cv2.GaussianBlur(out, (ksize, ksize), 0)\n",
    "\n",
    "    # JPEG compression\n",
    "    if random.random() < 0.5:\n",
    "        quality = random.randint(10, 60)\n",
    "        encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), quality]\n",
    "        _, enc = cv2.imencode(\".jpg\", out, encode_param)\n",
    "        out = cv2.imdecode(enc, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # Downscale → Upscale\n",
    "    if random.random() < 0.3:\n",
    "        h, w = out.shape[:2]\n",
    "        factor = random.choice([2, 4])\n",
    "        small = cv2.resize(out, (w // factor, h // factor), interpolation=cv2.INTER_AREA)\n",
    "        out   = cv2.resize(small, (w, h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# ── DIV2K Degraded Dataset ────────────────────────────────────────────\n",
    "class DIV2KDegradedDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Повертає пару (noisy, clean) для синтетичної задачі відновлення.\n",
    "\n",
    "    Із кожного чистого HR-зображення DIV2K вирізається патч;\n",
    "    потім до нього застосовуються синтетичні деградації.\n",
    "    Інтерфейс сумісний із DenoisingDataset: ключі 'noisy' і 'clean'.\n",
    "\n",
    "    Параметри\n",
    "    ----------\n",
    "    files        : список шляхів до HR-зображень\n",
    "    patch_size   : розмір кропу\n",
    "    augment      : якщо True — застосовуються flip/rotate аугментації\n",
    "    grayscale    : True → виводить 1-канальні тензори (як у DenoisingDataset)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        files: List[Path],\n",
    "        patch_size: int = PATCH_SIZE,\n",
    "        augment: bool = True,\n",
    "        grayscale: bool = False,\n",
    "    ):\n",
    "        self.files      = files\n",
    "        self.patch_size = patch_size\n",
    "        self.augment    = augment\n",
    "        self.grayscale  = grayscale\n",
    "\n",
    "        self._aug = A.Compose([\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "        ]) if augment else None\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        img_bgr = cv2.imread(str(self.files[idx]))\n",
    "        clean   = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # random crop\n",
    "        h, w = clean.shape[:2]\n",
    "        ps   = self.patch_size\n",
    "        if h > ps and w > ps:\n",
    "            y     = random.randint(0, h - ps)\n",
    "            x     = random.randint(0, w - ps)\n",
    "            clean = clean[y : y + ps, x : x + ps]\n",
    "        else:\n",
    "            clean = cv2.resize(clean, (ps, ps), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # flip / rotate\n",
    "        if self._aug:\n",
    "            clean = self._aug(image=clean)[\"image\"]\n",
    "\n",
    "        # синтетична деградація на копії\n",
    "        noisy = apply_degradation(clean)\n",
    "\n",
    "        if self.grayscale:\n",
    "            clean = cv2.cvtColor(clean, cv2.COLOR_RGB2GRAY)[..., None]\n",
    "            noisy = cv2.cvtColor(noisy, cv2.COLOR_RGB2GRAY)[..., None]\n",
    "\n",
    "        clean_t = torch.from_numpy(clean).permute(2, 0, 1).float() / 255.0\n",
    "        noisy_t = torch.from_numpy(noisy).permute(2, 0, 1).float() / 255.0\n",
    "\n",
    "        return {\"noisy\": noisy_t, \"clean\": clean_t}\n",
    "\n",
    "\n",
    "# ── Denoising Dataset ─────────────────────────────────────────────────\n",
    "class DenoisingDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Повертає пару (noisy, clean) для задачі відновлення документів.\n",
    "\n",
    "    Параметри\n",
    "    ----------\n",
    "    noisy_files : список шляхів до зашумлених зображень\n",
    "    clean_dir   : папка з відповідними «чистими» зображеннями\n",
    "    patch_size  : розмір кропу (0 = без кропу, повне зображення)\n",
    "    augment     : якщо True — flip/rotate аугментації\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        noisy_files: List[Path],\n",
    "        clean_dir: Path,\n",
    "        patch_size: int = PATCH_SIZE,\n",
    "        augment: bool = False,\n",
    "    ):\n",
    "        self.pairs: List[Tuple[Path, Path]] = []\n",
    "        for nf in noisy_files:\n",
    "            cf = clean_dir / nf.name\n",
    "            if cf.exists():\n",
    "                self.pairs.append((nf, cf))\n",
    "\n",
    "        self.patch_size = patch_size\n",
    "        self._aug = A.Compose([\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "        ], additional_targets={\"clean\": \"image\"}) if augment else None\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        noisy_path, clean_path = self.pairs[idx]\n",
    "\n",
    "        noisy = cv2.imread(str(noisy_path), cv2.IMREAD_GRAYSCALE)\n",
    "        clean = cv2.imread(str(clean_path), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # спільний crop\n",
    "        combined = np.stack([noisy, clean], axis=-1)\n",
    "        ps = self.patch_size\n",
    "        if ps and combined.shape[0] > ps and combined.shape[1] > ps:\n",
    "            h, w = combined.shape[:2]\n",
    "            y = random.randint(0, h - ps)\n",
    "            x = random.randint(0, w - ps)\n",
    "            combined = combined[y : y + ps, x : x + ps]\n",
    "\n",
    "        noisy_out = combined[..., 0:1]\n",
    "        clean_out = combined[..., 1:2]\n",
    "\n",
    "        if self._aug:\n",
    "            aug     = self._aug(image=noisy_out, clean=clean_out)\n",
    "            noisy_t = torch.from_numpy(aug[\"image\"]).permute(2, 0, 1)\n",
    "            clean_t = torch.from_numpy(aug[\"clean\"]).permute(2, 0, 1)\n",
    "        else:\n",
    "            noisy_t = torch.from_numpy(noisy_out).permute(2, 0, 1)\n",
    "            clean_t = torch.from_numpy(clean_out).permute(2, 0, 1)\n",
    "\n",
    "        return {\n",
    "            \"noisy\": noisy_t.float() / 255.0,\n",
    "            \"clean\": clean_t.float() / 255.0,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcfa539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIV2K total :  800\n",
      "  train     :  720\n",
      "  val       :   80\n",
      "\n",
      "Denoising total :  144\n",
      "  train         :  130\n",
      "  val           :   14\n",
      "\n",
      "DIV2K degraded train : 720 samples\n",
      "DIV2K degraded val   : 80   samples\n",
      "Denoising train      : 130 samples\n",
      "Denoising val        : 14   samples\n",
      "\n",
      "DataLoaders готові ✓\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ── Спліт DIV2K_TRAIN_HR → синтетичний датасет ───────────────────────\n",
    "div2k_all_files   = gather_images(DIV2K_TRAIN_HR_DIR)\n",
    "div2k_train_files, div2k_val_files = make_split(div2k_all_files)\n",
    "\n",
    "print(f\"DIV2K total : {len(div2k_all_files):>4}\")\n",
    "print(f\"  train     : {len(div2k_train_files):>4}\")\n",
    "print(f\"  val       : {len(div2k_val_files):>4}\")\n",
    "\n",
    "# ── Спліт Denoising (реальні пари) ───────────────────────────────────\n",
    "denoising_noisy_all       = gather_images(DENOISING_TRAIN_DIR)\n",
    "den_train_noisy, den_val_noisy = make_split(denoising_noisy_all)\n",
    "\n",
    "print(f\"\\nDenoising total : {len(denoising_noisy_all):>4}\")\n",
    "print(f\"  train         : {len(den_train_noisy):>4}\")\n",
    "print(f\"  val           : {len(den_val_noisy):>4}\")\n",
    "\n",
    "# ── Інстанціювання датасетів ──────────────────────────────────────────\n",
    "ds_div2k_train = DIV2KDegradedDataset(div2k_train_files, augment=True,  grayscale=False)\n",
    "ds_div2k_val   = DIV2KDegradedDataset(div2k_val_files,   augment=False, grayscale=False)\n",
    "\n",
    "ds_den_train   = DenoisingDataset(den_train_noisy, DENOISING_CLEANED_DIR, augment=True)\n",
    "ds_den_val     = DenoisingDataset(den_val_noisy,   DENOISING_CLEANED_DIR, augment=False)\n",
    "\n",
    "print(f\"\\nDIV2K degraded train : {len(ds_div2k_train)} samples\")\n",
    "print(f\"DIV2K degraded val   : {len(ds_div2k_val)}   samples\")\n",
    "print(f\"Denoising train      : {len(ds_den_train)} samples\")\n",
    "print(f\"Denoising val        : {len(ds_den_val)}   samples\")\n",
    "\n",
    "\n",
    "# https://docs.pytorch.org/docs/stable/notes/windows.html#usage-multiprocessing\n",
    "_MP_CTX = \"spawn\" if sys.platform.startswith(\"win\") else \"fork\"\n",
    "\n",
    "dl_div2k_train = DataLoader(ds_div2k_train, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                            num_workers=NUM_WORKERS, pin_memory=True, drop_last=True,\n",
    "                            multiprocessing_context=_MP_CTX)\n",
    "dl_div2k_val   = DataLoader(ds_div2k_val,   batch_size=BATCH_SIZE, shuffle=False,\n",
    "                            num_workers=NUM_WORKERS, pin_memory=True,\n",
    "                            multiprocessing_context=_MP_CTX)\n",
    "\n",
    "dl_den_train   = DataLoader(ds_den_train, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                            num_workers=NUM_WORKERS, pin_memory=True, drop_last=True,\n",
    "                            multiprocessing_context=_MP_CTX)\n",
    "dl_den_val     = DataLoader(ds_den_val,   batch_size=BATCH_SIZE, shuffle=False,\n",
    "                            num_workers=NUM_WORKERS, pin_memory=True,\n",
    "                            multiprocessing_context=_MP_CTX)\n",
    "\n",
    "print(\"\\nDataLoaders готові ✓\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1bb9ca93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m1\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    from multiprocessing.spawn import spawn_main; \u001b[31mspawn_main\u001b[0m\u001b[1;31m(tracker_fd=99, pipe_handle=144)\u001b[0m\n",
      "                                                  \u001b[31m~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/invp/.local/share/uv/python/cpython-3.14.3-linux-x86_64-gnu/lib/python3.14/multiprocessing/spawn.py\"\u001b[0m, line \u001b[35m122\u001b[0m, in \u001b[35mspawn_main\u001b[0m\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \u001b[35m\"/home/invp/.local/share/uv/python/cpython-3.14.3-linux-x86_64-gnu/lib/python3.14/multiprocessing/spawn.py\"\u001b[0m, line \u001b[35m132\u001b[0m, in \u001b[35m_main\u001b[0m\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "\u001b[1;35mAttributeError\u001b[0m: \u001b[35mmodule '__main__' has no attribute 'DIV2KDegradedDataset'\u001b[0m\n",
      "  File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m1\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    from multiprocessing.spawn import spawn_main; \u001b[31mspawn_main\u001b[0m\u001b[1;31m(tracker_fd=99, pipe_handle=113)\u001b[0m\n",
      "                                                  \u001b[31m~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/invp/.local/share/uv/python/cpython-3.14.3-linux-x86_64-gnu/lib/python3.14/multiprocessing/spawn.py\"\u001b[0m, line \u001b[35m122\u001b[0m, in \u001b[35mspawn_main\u001b[0m\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \u001b[35m\"/home/invp/.local/share/uv/python/cpython-3.14.3-linux-x86_64-gnu/lib/python3.14/multiprocessing/spawn.py\"\u001b[0m, line \u001b[35m132\u001b[0m, in \u001b[35m_main\u001b[0m\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "\u001b[1;35mAttributeError\u001b[0m: \u001b[35mmodule '__main__' has no attribute 'DIV2KDegradedDataset'\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m1\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    from multiprocessing.spawn import spawn_main; \u001b[31mspawn_main\u001b[0m\u001b[1;31m(tracker_fd=99, pipe_handle=109)\u001b[0m\n",
      "                                                  \u001b[31m~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/invp/.local/share/uv/python/cpython-3.14.3-linux-x86_64-gnu/lib/python3.14/multiprocessing/spawn.py\"\u001b[0m, line \u001b[35m122\u001b[0m, in \u001b[35mspawn_main\u001b[0m\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \u001b[35m\"/home/invp/.local/share/uv/python/cpython-3.14.3-linux-x86_64-gnu/lib/python3.14/multiprocessing/spawn.py\"\u001b[0m, line \u001b[35m132\u001b[0m, in \u001b[35m_main\u001b[0m\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "\u001b[1;35mAttributeError\u001b[0m: \u001b[35mmodule '__main__' has no attribute 'DIV2KDegradedDataset'\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m1\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    from multiprocessing.spawn import spawn_main; \u001b[31mspawn_main\u001b[0m\u001b[1;31m(tracker_fd=99, pipe_handle=106)\u001b[0m\n",
      "                                                  \u001b[31m~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/home/invp/.local/share/uv/python/cpython-3.14.3-linux-x86_64-gnu/lib/python3.14/multiprocessing/spawn.py\"\u001b[0m, line \u001b[35m122\u001b[0m, in \u001b[35mspawn_main\u001b[0m\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \u001b[35m\"/home/invp/.local/share/uv/python/cpython-3.14.3-linux-x86_64-gnu/lib/python3.14/multiprocessing/spawn.py\"\u001b[0m, line \u001b[35m132\u001b[0m, in \u001b[35m_main\u001b[0m\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "\u001b[1;35mAttributeError\u001b[0m: \u001b[35mmodule '__main__' has no attribute 'DIV2KDegradedDataset'\u001b[0m\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 31746) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/test/code/uni_cv/.venv/lib/python3.14/site-packages/torch/utils/data/dataloader.py:1310\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1309\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1310\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1311\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.14.3-linux-x86_64-gnu/lib/python3.14/queue.py:210\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    209\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnot_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._qsize():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.14.3-linux-x86_64-gnu/lib/python3.14/threading.py:373\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m     gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/test/code/uni_cv/.venv/lib/python3.14/site-packages/torch/utils/data/_utils/signal_handling.py:73\u001b[39m, in \u001b[36m_set_SIGCHLD_handler.<locals>.handler\u001b[39m\u001b[34m(signum, frame)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhandler\u001b[39m(signum, frame) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     71\u001b[39m     \u001b[38;5;66;03m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[32m     72\u001b[39m     \u001b[38;5;66;03m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[43m_error_if_any_worker_fails\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m previous_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mRuntimeError\u001b[39m: DataLoader worker (pid 31746) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[107]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ── Санітарна перевірка батчів ────────────────────────────────────────\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m batch_div2k = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdl_div2k_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m batch_den   = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(dl_den_train))\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, batch \u001b[38;5;129;01min\u001b[39;00m [(\u001b[33m\"\u001b[39m\u001b[33mDIV2K degraded\u001b[39m\u001b[33m\"\u001b[39m, batch_div2k), (\u001b[33m\"\u001b[39m\u001b[33mDenoising\u001b[39m\u001b[33m\"\u001b[39m, batch_den)]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/test/code/uni_cv/.venv/lib/python3.14/site-packages/torch/utils/data/dataloader.py:741\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    738\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    739\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    740\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m741\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    742\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    743\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    744\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    745\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    746\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    747\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/test/code/uni_cv/.venv/lib/python3.14/site-packages/torch/utils/data/dataloader.py:1524\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1520\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding <= \u001b[32m0\u001b[39m:\n\u001b[32m   1521\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m   1522\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mInvalid iterator state: shutdown or no outstanding tasks when fetching next data\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1523\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1524\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1525\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1526\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1527\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/test/code/uni_cv/.venv/lib/python3.14/site-packages/torch/utils/data/dataloader.py:1473\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1471\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m   1472\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory_thread.is_alive():\n\u001b[32m-> \u001b[39m\u001b[32m1473\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1474\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1475\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/test/code/uni_cv/.venv/lib/python3.14/site-packages/torch/utils/data/dataloader.py:1323\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1321\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) > \u001b[32m0\u001b[39m:\n\u001b[32m   1322\u001b[39m     pids_str = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mstr\u001b[39m(w.pid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[32m-> \u001b[39m\u001b[32m1323\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1324\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) exited unexpectedly\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1325\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1326\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue.Empty):\n\u001b[32m   1327\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mRuntimeError\u001b[39m: DataLoader worker (pid(s) 31746) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "\n",
    "# ── Санітарна перевірка батчів ────────────────────────────────────────\n",
    "batch_div2k = next(iter(dl_div2k_train))\n",
    "batch_den   = next(iter(dl_den_train))\n",
    "\n",
    "for name, batch in [(\"DIV2K degraded\", batch_div2k), (\"Denoising\", batch_den)]:\n",
    "    n  = batch[\"noisy\"]\n",
    "    c  = batch[\"clean\"]\n",
    "    print(f\"{name}\")\n",
    "    print(f\"  noisy : {tuple(n.shape)}  dtype={n.dtype}  range=[{n.min():.2f}, {n.max():.2f}]\")\n",
    "    print(f\"  clean : {tuple(c.shape)}  dtype={c.dtype}  range=[{c.min():.2f}, {c.max():.2f}]\")\n",
    "\n",
    "# Візуалізація кількох прикладів із DIV2K\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "for i in range(4):\n",
    "    noisy_np = batch_div2k[\"noisy\"][i].permute(1, 2, 0).numpy()\n",
    "    clean_np = batch_div2k[\"clean\"][i].permute(1, 2, 0).numpy()\n",
    "    axes[0, i].imshow(np.clip(clean_np, 0, 1))\n",
    "    axes[0, i].set_title(f\"Clean #{i}\")\n",
    "    axes[0, i].axis(\"off\")\n",
    "    axes[1, i].imshow(np.clip(noisy_np, 0, 1))\n",
    "    axes[1, i].set_title(f\"Degraded #{i}\")\n",
    "    axes[1, i].axis(\"off\")\n",
    "plt.suptitle(\"DIV2K: clean vs synthetic degradation\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "creative-denoising-autoencoder (3.14.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
